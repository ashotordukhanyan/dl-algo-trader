{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl_agent import Agent\n",
    "from env_market import mkt_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Created\n",
      "Episode: 0 Total Reward: -0.0036844383352763544\n",
      "Episode: 1 Total Reward: -1.2089759111999883\n",
      "Episode: 2 Total Reward: 1.5342413102845494\n",
      "Episode: 3 Total Reward: 1.7500523461882367\n",
      "Episode: 4 Total Reward: 2.7985137290858804\n",
      "Episode: 5 Total Reward: 2.4001522298448763\n",
      "Episode: 6 Total Reward: -0.1260889347450866\n",
      "Episode: 7 Total Reward: -0.7801626792480565\n",
      "Episode: 8 Total Reward: 0.2973546752977381\n",
      "Episode: 9 Total Reward: 1.8506453182348415\n",
      "Episode: 10 Total Reward: -1.7537064511789249\n",
      "Episode: 11 Total Reward: 5.168290226711357\n",
      "Episode: 12 Total Reward: 3.786324511229883\n",
      "Episode: 13 Total Reward: 4.464071501269289\n",
      "Episode: 14 Total Reward: -3.2704667999840678\n",
      "Episode: 15 Total Reward: 0.9782964681037484\n",
      "Episode: 16 Total Reward: 1.5630939859907957\n",
      "Episode: 17 Total Reward: 2.4204091302327617\n",
      "Episode: 18 Total Reward: 5.226600015508604\n",
      "Episode: 19 Total Reward: 1.6875504728533306\n",
      "Episode: 20 Total Reward: 0.32969823700447526\n",
      "Episode: 21 Total Reward: 0.7899248255620296\n",
      "Episode: 22 Total Reward: -0.6659809309136144\n",
      "Episode: 23 Total Reward: 5.673946759589577\n",
      "Episode: 24 Total Reward: 0.06255146953770235\n",
      "Episode: 25 Total Reward: 5.243649977039462\n",
      "Episode: 26 Total Reward: 2.5417323543647763\n",
      "Episode: 27 Total Reward: 0.8142982904831296\n",
      "Episode: 28 Total Reward: 0.8884481718968382\n",
      "Episode: 29 Total Reward: 3.915086976726587\n",
      "Episode: 30 Total Reward: 3.133758141685852\n",
      "Episode: 31 Total Reward: 6.626652121763302\n",
      "Episode: 32 Total Reward: 2.5116188631622207\n",
      "Episode: 33 Total Reward: 2.9832542536205255\n",
      "Episode: 34 Total Reward: 0.31228245027748197\n",
      "Episode: 35 Total Reward: 3.4219158786368133\n",
      "Episode: 36 Total Reward: 1.0084150999539052\n",
      "Episode: 37 Total Reward: 2.784177117699419\n",
      "Episode: 38 Total Reward: 0.4270510550769941\n",
      "Episode: 39 Total Reward: -0.5383265053396608\n",
      "Episode: 40 Total Reward: 1.6830094810332412\n",
      "Episode: 41 Total Reward: 2.7321235576685394\n",
      "Episode: 42 Total Reward: -3.362960155572819\n",
      "Episode: 43 Total Reward: 6.883369200627516\n",
      "Episode: 44 Total Reward: -1.210153054951723\n",
      "Episode: 45 Total Reward: 2.710643666348642\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "trade_agent = Agent()\n",
    "env = mkt_env()\n",
    "Agent.run(trade_agent, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv(\"reward.txt\",sep=' ')\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv(\"reward.txt\",sep=' ')\n",
    "reward = dat['reward']\n",
    "tim = dat['time']\n",
    "\n",
    "plt.plot(reward, color='red', linewidth=0.5)\n",
    "plt.plot(reward.rolling(window=10).mean(), color='green', linewidth=0.5)\n",
    "plt.plot(reward.rolling(window=20).mean(), color='blue', linewidth=0.5)\n",
    "plt.plot(0,color=\"black\", linewidth=1)\n",
    "plt.xlabel(\"TIME\")\n",
    "plt.ylabel(\"REWARD\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
